{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep fully connected neural networks for image classification\n",
    "<span style=\"font-size:9pt;\">\n",
    "author: MWLafarge (m.w.lafarge@tue.nl); affiliation: Eindhoven University of Technology; created: Feb 2020\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries\n",
    "In this exercise you will implement a deep fully connected neural network for image classification using the __Keras__ framework with a Tensorflow backend.  \n",
    "The goal is to analyze the training of __deep__ neural network models for complex problems with high dimensionality.\n",
    "\n",
    "This exercise will focus on a binary classification problem with histopathology images. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# environement setup\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib widget\n",
    "#%matplotlib inline\n",
    "\n",
    "# system libraries\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# computational libraries\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# utility functions for this exercise\n",
    "from utils_ex2 import plot_image_batch, Monitoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the dataset\n",
    "\n",
    "The dataset for this exercise is derived from the __PCam__ benchmark dataset created by B. Veeling et al. ([github.com/basveeling/pcam](https://github.com/basveeling/pcam)) that in turn originates from the [CAMELYON16 challenge](https://camelyon16.grand-challenge.org/). \n",
    "\n",
    "The PCam dataset consist of RGB color images of size 96 $\\times$ 96 pixels extracted from histological sections of sentinel lymph node tissue of breast cancer patients. Each image is annotated with a binary label indicating presence of metastatic tissue in the patch.\n",
    "\n",
    "For the purpose of this exercise, the original PCam dataset was subsampled to 20000 training images and 2000 test images, balanced across the two classes.  \n",
    "Furthermore, to enable faster processing the images were cropped to the central region of 64 $\\times$ 64 pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_BASE_DIR = os.getcwd() # current working directory\n",
    "\n",
    "def load_data_helper(path):\n",
    "    data_dict = np.load(path) \n",
    "    data_points = data_dict[\"images\"]\n",
    "    data_labels = data_dict[\"labels\"]\n",
    "    \n",
    "    return data_points, data_labels\n",
    "\n",
    "path_train = PATH_BASE_DIR + os.sep + \"../data/data_smallPCam_training.npz\"\n",
    "path_test  = PATH_BASE_DIR + os.sep + \"../data/data_smallPCam_test.npz\"\n",
    "data_images_train, data_labels_train = load_data_helper(path_train)\n",
    "data_images_test, data_labels_test   = load_data_helper(path_test)\n",
    "    \n",
    "print(\"Imported training points: \", data_images_train.shape)\n",
    "print(\"Imported training labels: \", data_labels_train.shape)\n",
    "\n",
    "print(\"Imported test points: \", data_images_test.shape)\n",
    "print(\"Imported test labels: \", data_labels_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's visualize a few examples.  As it can be seen, the class label of a patch (1: tumor, 0: not tumor) is not obvious to non-experts (this task experience with analyzing histopathology images). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_indices = [np.random.randint(data_images_train.shape[0]) for _i in range(8)]\n",
    "\n",
    "batch_images = data_images_train[random_indices,]\n",
    "batch_labels = data_labels_train[random_indices,]\n",
    "\n",
    "plot_image_batch(batch_images, batch_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a classifier\n",
    "We want to create a model that takes high-dimensional vectors (images) as input and outputs the likelihood of the class label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the graph operations\n",
    "As with the first exercise, let's first instantiate all the components that we will use to construct the network:\n",
    "- __tf.keras.Input()__ placeholder that takes vectors of size 64$\\times$64$\\times$3.  \n",
    "- several __tf.keras.layers.Dense()__ layers that will constitute the network.\n",
    "\n",
    "  \n",
    "Note that the high-dimensionality of the input creates a risk for the model to overfit the training dataset, so some sort of mitigation strategy is required. One option is to use regularization such as $L_2$ regularization. We will also define a $L_2$ regularizer (__tf.keras.regularizers.l2()__) that will be used during training. The regularizer can be passed as an argument during the instantiation of the layers. __tf.keras__ includes other regularizers that can be easily associated with the model components (see [tf.keras.regularizers documentation](https://www.tensorflow.org/api_docs/python/tf/keras/regularizers))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regularizer object\n",
    "weight_decay = 0.01\n",
    "regularizer = tf.keras.regularizers.l2(l=weight_decay)\n",
    "\n",
    "# placeholder for the image data\n",
    "# note that the image data is flattened to one dimension\n",
    "images_size = 64 * 64 * 3\n",
    "inputs = tf.keras.Input(shape=(images_size,))\n",
    "\n",
    "# model components\n",
    "layer1   = tf.keras.layers.Dense(64, activation='relu', kernel_regularizer=regularizer)\n",
    "layer2   = tf.keras.layers.Dense(16, activation='relu', kernel_regularizer=regularizer)\n",
    "layer3   = tf.keras.layers.Dense(8, activation='relu', kernel_regularizer=regularizer)\n",
    "\n",
    "layerOut = tf.keras.layers.Dense(1, activation='sigmoid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connecting the graph and instantiating the model\n",
    "We can now join the graph components to define the model __output__ as a function of the __input placeholder__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = layerOut(layer3(layer2(layer1(inputs))))\n",
    "\n",
    "model = tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing to train the model\n",
    "\n",
    "As before, we will use binary cross entropy loss and stochastic gradient descent with momentum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross-entropy loss between the distribution of ground truth labels and the model predictions\n",
    "loss = tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "# stochastic gradient descent with momentum\n",
    "optimizer = tf.keras.optimizers.SGD(\n",
    "    learning_rate = 0.01,\n",
    "    momentum      = 0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling the model\n",
    "We finally configure the model for training by indicating the loss, the optimizer and performance metrics to be computed during training.  \n",
    "\n",
    "We use __model.summary()__ to display and check the model architecture we implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = optimizer,\n",
    "    loss      = tf.keras.losses.BinaryCrossentropy(),\n",
    "    metrics   = [\"accuracy\"])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a data generator\n",
    "\n",
    "Since this is a large dataset, it is __memory-wise expensive and unnecessary to load the whole dataset in memory__. Therefore, a solution is to create a generator that will read random __mini-batches__ of samples every training iteration.\n",
    "\n",
    "We can define a __\"generator\"__ object with __tf.keras__ that will be called automatically during the training loop. We can implement our custom generator as a class that inherits from __tf.keras.utils.Sequence__. At every iteration, keras expects the method __\\_\\_getitem\\_\\___ to return 2 tensors: \n",
    "- a batch of images\n",
    "- a batch of the corresponding labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataGenerator(tf.keras.utils.Sequence):\n",
    "    \"\"\" DataGenerator herited from tf.keras.utils.Sequence\n",
    "        Input: image data, label data\n",
    "        __getitem__: Returns random samples (mini-batches) drawn from the data\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data_images, data_labels):\n",
    "        self.batch_size = 32\n",
    "        \n",
    "        self.data_images = data_images\n",
    "        self.data_labels = data_labels\n",
    "        self.data_size   = data_images.shape[0]\n",
    "        \n",
    "        self.scan_idx    = 0\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(self.data_size / self.batch_size)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_images = []\n",
    "        batch_labels = []\n",
    "        for _i in range(self.batch_size):\n",
    "            batch_images.append(self.data_images[self.scan_idx,])\n",
    "            batch_labels.append(self.data_labels[self.scan_idx])\n",
    "        \n",
    "            self.scan_idx += 1 # Loop over available images\n",
    "            self.scan_idx %= self.data_size\n",
    "            \n",
    "        batch_images = np.stack(batch_images, axis=0)\n",
    "        batch_labels = np.array(batch_labels)\n",
    "        \n",
    "        shape_flat = [-1, batch_images.shape[1] * batch_images.shape[2] * batch_images.shape[3]]\n",
    "        batch_images = np.reshape(batch_images, shape_flat)\n",
    "        \n",
    "        batch_images = 2.0 * (batch_images / 255.0 - 0.5) # Images are rescaled in [-1,1]\n",
    "        \n",
    "        return batch_images, batch_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can instantiate 2 generators: one to generate mini-batches of the training data, one to generate mini-batches of the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataGenerator_train = dataGenerator(data_images_train, data_labels_train)\n",
    "dataGenerator_test  = dataGenerator(data_images_test, data_labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally lets check what keras receives when the generator are called:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arbitrary_iteration_idx = 42\n",
    "train_images_batch, train_labels_batch = dataGenerator_train[arbitrary_iteration_idx]\n",
    "\n",
    "print(\"Mini-batch of images has shape: \", train_images_batch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model and monitoring the training process\n",
    "\n",
    "Now that our generators are instantiated, we can train our model.\n",
    "This time, we will use __tf.keras.Model.fit\\_generator__ function to start the training procedure by feeding data generators instead of data arrays. Look at the documentation of [tf.keras.Model.fit\\_generator](https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit\\_generator) for more details.\n",
    "\n",
    "To get a better insight of the learned weights, the Monitor callback for this exercise will show visualizations of the weights of the first layer. The weights are visualized as images. Note that the output of each neuron in the first layer is the input image $\\times$ weights image + bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbEpochs  = 500\n",
    "\n",
    "model.fit_generator(\n",
    "    generator = dataGenerator_train,\n",
    "    steps_per_epoch = 10,\n",
    "    epochs          = nbEpochs,\n",
    "\n",
    "    validation_data  = dataGenerator_test,\n",
    "    validation_freq  = 10,\n",
    "    validation_steps = 1,\n",
    "\n",
    "    verbose   = 1,\n",
    "    callbacks = [Monitoring(layerTracking=layer1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model\n",
    "Once the model is trained, we want to quantify its performances on the hold-out test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We evaluate the model on test data\n",
    "eval_out = model.evaluate_generator(\n",
    "    generator = dataGenerator_test,\n",
    "    verbose   = 1)\n",
    "\n",
    "print(\"Accuracy on test set: \", eval_out[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing some predictions\n",
    "Let's select a sample of test images and compare the predictions with the true class labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we use the test generator to create batches of test images\n",
    "arbitrary_iteration_idx = 42\n",
    "batch_test_images, batch_test_labels = dataGenerator_test[arbitrary_iteration_idx]\n",
    "batch_test_images = batch_test_images[:8] # Selection of a small sample\n",
    "batch_test_labels = batch_test_labels[:8]\n",
    "\n",
    "# Then we get the prediction of the mode\n",
    "tensor_predictions = model.predict(\n",
    "    x = batch_test_images)\n",
    "\n",
    "# We format the results in a list for visualization\n",
    "list_results = [\"True Class [{}] \\n P(y=1|x) = {}\".format(true_y, str(pred_y[0])[:5]) \n",
    "                for true_y, pred_y in zip(batch_test_labels, tensor_predictions)]\n",
    "\n",
    "# We reshape the images to their format of origin\n",
    "batch_images_unflattened = np.reshape(batch_test_images, [-1,64,64,3]) #-- Unflattening\n",
    "batch_images_unflattened = 255.0 * (batch_images_unflattened + 1.0) / 2.0 #-- Rescaling\n",
    "batch_images_unflattened = batch_images_unflattened.astype(np.uint8) #-- 8-bit conversion\n",
    "\n",
    "plot_image_batch(batch_images_unflattened, list_results) #-- We finally visualize the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "\n",
    "## The effect of the model architecture\n",
    "\n",
    "Experiment with different neural network architectures and observe the training process (using the training and test loss curves), the parameters of the first layer (using the visualization of the weights) and the classification accuracy. You can create new neural network architectures by varying the depth of the network (number of layers) and/or the number of neurons in each layer.\n",
    "\n",
    "## The effect of the training procedure and regularization\n",
    "\n",
    "Experiment with different parameters of the optimizer(learning rate and the momentum) and observe the training process using the training and test loss curves. Try varying the $L_2$ regularization factor. What is the effect of increasing the regularization on the appearance of the weight images?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
